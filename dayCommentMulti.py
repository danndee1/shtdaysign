import os
import re
import time
import httpx
import traceback
import random
import math
import configparser
from datetime import datetime, timedelta
from contextlib import contextmanager
from bs4 import BeautifulSoup
from xml.etree import ElementTree as ET
from flaresolverr import FlareSolverrHTTPClient

# åŠ è½½é…ç½®æ–‡ä»¶
config = configparser.ConfigParser()
config.read('config.ini', encoding='utf-8')

# è·å–ä»£ç†æ± é…ç½®
proxy_pool = [proxy.strip() for proxy in config.get('proxy_pool', 'proxies').split('\n') if proxy.strip()]
max_retries = config.getint('retry', 'max_retries')
retry_delay = config.getint('retry', 'retry_delay')

SEHUATANG_HOST = 'www.sehuatang.net'
DEFAULT_USER_AGENT = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36'

FID = 103  # é«˜æ¸…ä¸­æ–‡å­—å¹•

AUTO_REPLIES = (
    'è¿™èº«ææœ‰ç‚¹æ„æ€',
    'èƒ¸éƒ¨çœ‹ç€æŒºä¸é”™',
    'å°é¢è®©äººå¿ƒåŠ¨å•Š',
    'ä½è°ƒæ”¯æŒä¸€ä¸‹å§',
    'ç”»é¢æœ‰ç‚¹å°æ’©äºº',
    'è¿™ç‰‡å­å€¼å¾—ä¸€ç§',
    'å°é¢è®¾è®¡å¾ˆç”¨å¿ƒ',
    'æš—æˆ³æˆ³åœ°æŒºå¸¦æ„Ÿ',
    'è¿™èµ„æºæœ‰ç‚¹å‘³é“',
    'çœ‹ç€å¿ƒæƒ…è¿˜ä¸é”™',
    'èº«æç¡®å®æŒºåœ¨çº¿',
    'é»˜é»˜ç‚¹ä¸ªèµå…ˆ',
    'è¿™ç»†èŠ‚è®©äººä¸Šå¤´',
    'èµå¿ƒæ‚¦ç›®å°±å¤Ÿäº†',
    'å†…å¿ƒå·²è¢«ç‚¹ç‡ƒäº†',
    'è¿™è°èƒ½ä¸å¿ƒåŠ¨å‘¢',
    'å…‹åˆ¶ä¸ä½æƒ³çœ‹äº†',
    'æ”¯æŒä¸€ä¸‹å¾ˆåˆç†',
    'çœŸæŒºä¸é”™ä½è°ƒçˆ±',
    'è¿™ç”»é¢æœ‰ç‚¹é¡¶å•Š',
    'å¿ƒé‡Œå·²ç»æ”¶è—äº†',
    'æ¼”æŠ€è®©äººæœ‰ç‚¹è¿·',
    'è¿™ç³»åˆ—æš—è—æƒŠå–œ',
    'èƒ¸éƒ¨æ›²çº¿æŒºå‹¾äºº',
    'çœ‹ç€æ„Ÿè§‰è¿˜è¡Œå§',
    'å…ˆæ”¶è—å†è¯´åˆ«çš„',
    'å†…å¿ƒæ³¢æ¾œå·²èµ·ä¼',
    'æ¥¼ä¸»æ‡‚æˆ‘å¿ƒæ„å•Š',
    'ä½œå“æœ‰ç‚¹å°ç²¾è‡´',
    'çœ‹ç‰‡å¿ƒæƒ…å¾ˆå¾®å¦™',
    'å¥½ç‰‡å¾—æ…¢æ…¢å“å‘³',
    'æœŸå¾…ä¸‹æ¬¡æ›´ç²¾å½©',
    'æ¥¼ä¸»æš—è—åŠŸåŠ›æ·±',
    'é»˜é»˜æ”¯æŒå¾ˆå¯ä»¥',
    'å¥½äººè‡ªæœ‰å¥½èµ„æº',
    'å¤§ç¥ä½è°ƒåˆç»™åŠ›',
    'èµ„æºçœ‹ç€å¾ˆèˆ’æœ',
    'è¿™ç‰‡å­æœ‰ç‚¹å‘³é“',
    'å€¼å¾—é™é™æ¬£èµä¸‹',
    'å¥½ä¸œè¥¿å¾—ç»†ç»†çœ‹',
    'å…ˆä¸‹è½½å“ä¸€å“å§',
    'æ¥¼ä¸»çœŸæ˜¯è—é¾™å•Š',
    'æ„Ÿè§‰æŒºä¸é”™å°±è¡Œ',
    'å‰å®³äº†æˆ‘çš„å¿ƒåŠ¨',
    'èµ„æºæœ‰ç‚¹å°æƒŠå–œ',
    'ç»äº†å¾—æ…¢æ…¢æ„Ÿå—',
    'è¿™ç”»é¢æœ‰ç‚¹ä¸Šç˜¾',
    'èº«æè®©äººæš—è‡ªèµ',
    'å°é¢å·²æˆ³ä¸­æˆ‘å¿ƒ',
    'å†…å¿ƒå·²è¢«å½»åº•ç‡ƒ',
    'ç”»é¢ç¾å¾—æœ‰ç‚¹æ™•',
    'ç‚¹èµå¾—ä½è°ƒè¿›è¡Œ',
    'è¿™ç‰‡çœ‹ç€æœ‰å†…æ¶µ',
    'é¢œå€¼æš—æš—åœ¨çº¿å•Š',
    'æ‰‹æ³•æœ‰ç‚¹å°å·§å¦™',
    'å¥½çœ‹å¾—ä¸åŠ¨å£°è‰²',
    'è°çœ‹è°æš—è‡ªå–œæ¬¢',
    'å®Œç¾å¾—æœ‰ç‚¹è¿‡åˆ†',
    'å¿ƒåŠ¨è—åœ¨çœ¼ç¥é‡Œ',
    'æ”¶è—å¾—ä¸åŠ¨å£°è‰²',
    'èº«æè®©äººæš—æŒ‘çœ‰',
    'è¿™æ‰‹æ³•æœ‰ç‚¹ä¼šå•Š',
    'ç”»é¢æ„Ÿæœ‰ç‚¹æ»¡åˆ†',
    'çˆ±äº†å¾—è—å¿ƒé‡Œå¤´',
    'è¿™æ„Ÿè§‰æœ‰ç‚¹ä¸Šå¤´',
    'å®Œå…¨æš—æˆ³æˆ³å–œæ¬¢',
    'æ”¯æŒå¾—æœ‰ç‚¹å«è“„',
    'çœ‹äº†è¿˜æƒ³å·å·çœ‹',
    'è¿™ç‰‡å­æœ‰ç‚¹éŸµå‘³',
        'è¿™èº«æçœŸç»äº†',
    'å¥¶å­çœŸæ˜¯æ£’æäº†',
    'èƒ¸éƒ¨ç®€ç›´å®Œç¾å•Š',
    'å¿…é¡»å¤§åŠ›æ”¯æŒå‘€',
    'çœ‹ç€å°±çˆ½åˆ°é£èµ·',
    'è¿™ç‰‡å­ç»å¯¹ç»™åŠ›',
    'å°é¢ç¾å¾—å†’æ³¡äº†',
    'çœŸæ˜¯æœ‰ç‚¹å°åˆºæ¿€',
    'å°é¢èµçˆ†æ”¯æŒä¸€æ³¢',
    'å®åœ¨æ˜¯å¤ªæ£’äº†å§',
    'ä¸é”™ä¸é”™çˆ±äº†çˆ±äº†',
    'èº«æç«è¾£é¡¶ä¸ä½å•Š',
    'ç»ˆäºç­‰åˆ°å¥½è´§äº†',
    'è¿™èµ„æºçœ‹ç€å¸¦åŠ²',
    'ç”»é¢èµå¿ƒæ‚¦ç›®å•Š',
    'å¿«ä¹ç®€ç›´åœä¸ä¸‹æ¥',
    'è¿™è°èƒ½æ‰›å¾—ä½å•Š',
    'å®Œå…¨æ— æ³•æŠµæŒ¡ä½',
    'æ”¯æŒå¤§ä½¬å†²å†²å†²',
    'çœŸå¿ƒä¸é”™çˆ±æ­»äº†',
    'è°çœ‹äº†ä¸å¿ƒåŠ¨å•Š',
    'ç®€ç›´è®©äººæŠŠæŒä¸ä½',
    'æ¼”æŠ€åœ¨çº¿å¤ªä¼šäº†',
    'è¿™ç³»åˆ—è¶Šæ¥è¶Šæœ‰æ–™',
    'èƒ¸éƒ¨å¥½çœ‹é¡¶å‘±å‘±',
    'çœ‹ç€å°±è§‰å¾—å¸¦æ„Ÿ',
    'å®Œå…¨å¯ä»¥å†²ä¸€å†²',
    'å·²ç»æœæ–­æ”¶è—äº†',
    'æ¥¼ä¸»çœŸæ˜¯å¨æ­¦éœ¸æ°”',
    'ä½œå“ç²¾å½©é¡¶ä¸ä½',
    'çœ‹ç‰‡å¿ƒæƒ…è¶…æ„‰å¿«',
    'å¥½ç‰‡å¿…é¡»æ”¶è—å•Š',
    'æœŸå¾…æ›´å¤šç²¾å½©å†…å®¹',
    'æ¥¼ä¸»ç»™åŠ›é¡¶é¡¶é¡¶',
    'è¶…æ£’å¿…é¡»æ”¯æŒä¸‹',
    'å¥½äººä¸€ç”Ÿå¹³å®‰å‘',
    'è†œæ‹œå¤§ç¥å¤ªç‰›äº†',
    'èµ„æºä¼˜ç§€çˆ±ç–¯äº†',
    'è¿™ç‰‡å­çœŸå¿ƒå¤Ÿå‘³',
    'ç»å¯¹å€¼å¾—ä¸€çœ‹å•Š',
    'å¥½ä¸œè¥¿å¿…é¡»æ”¯æŒ',
    'èµ¶ç´§ä¸‹è½½æ¥æ¬£èµ',
    'æ¥¼ä¸»ç‰›é€¼é—ªé—ªå‘å…‰',
    'ç›¸å½“ä¸é”™çˆ±äº†çˆ±äº†',
    'å¤§ä½¬å‰å®³é¡¶èµ·æ¥',
    'èµ„æºç»èµå†²å†²å†²',
    'ç»äº†å¿…é¡»ç–¯ç‹‚çˆ±',
    'è¿™ä¹Ÿå¤ªé¡¶äº†å§å”§',
    'èº«æå®Œç¾ç»ç»å­',
    'å°é¢æ€å¾—æˆ‘å¿ƒåŠ¨',
    'å®Œå…¨é¡¶ä¸ä½è¯±æƒ‘',
    'ç”»é¢ç¾åˆ°ç‚¸è£‚äº†',
    'å¿…é¡»ç–¯ç‹‚ç‚¹èµå•Š',
    'è¿™ç‰‡æœ‰çœ‹å¤´å¸¦åŠ²',
    'é¢œå€¼åœ¨çº¿é¡¶ä¸ä½',
    'å¤ªä¼šæ’©äººäº†å§å”§',
    'å¥½çœ‹åˆ°ç›´æ¥ç‚¸äº†',
    'è°çœ‹äº†ä¸çˆ±ç–¯å•Š',
    'å®Œç¾åˆ°è®©äººçª’æ¯',
    'ç¬é—´å¿ƒåŠ¨æ”¶è—äº†',
    'ç›´æ¥æœæ–­æ”¶è—äº†',
    'èº«æç»äº†é¡¶ä¸ä½',
    'çœŸä¼šç©æˆ‘å¿ƒåŠ¨äº†',
    'ç”»é¢æ„Ÿæ»¡åˆ†èµçˆ†',
    'çˆ±äº†çˆ±äº†åœä¸ä¸‹',
    'è¿™ä¹Ÿå¤ªèµäº†å…„å¼Ÿ',
    'å®Œå…¨æˆ³ä¸­æˆ‘å¿ƒå·´',
    'å¿…é¡»æ”¯æŒä¸€æ³¢èµ°èµ·',
    'çœ‹äº†è¿˜æƒ³å†çœ‹å•Š',
    'è¿™ç‰‡å¤Ÿå‘³çœŸå¸¦æ„Ÿ',
)

def get_random_proxy():
    """ä»ä»£ç†æ± ä¸­éšæœºè·å–ä¸€ä¸ªä»£ç†"""
    if not proxy_pool:
        return None
    return random.choice(proxy_pool)

def create_proxy_dict(proxy_url):
    """åˆ›å»ºä»£ç†å­—å…¸"""
    if not proxy_url:
        return None
    return {
        'http': proxy_url,
        'https': proxy_url
    }

def daysign(
    cookies: dict,
    flaresolverr_url: str = None,
    flaresolverr_proxy: str = None,
    proxies: dict = None  # æ–°å¢çš„ proxies å‚æ•°ï¼Œç”¨äºä¼ å…¥ä»£ç†é…ç½®
) -> str:
    current_proxy = None
    used_proxies = set()  # è®°å½•å·²ä½¿ç”¨çš„ä»£ç†
    
    # å¦‚æœä¼ å…¥äº†ä»£ç†ï¼Œåˆ™ä½¿ç”¨ç¯å¢ƒå˜é‡ä»£ç†
    if proxies:
        print(f"ä½¿ç”¨ç¯å¢ƒå˜é‡ä»£ç†: {proxies}")
        current_proxy = proxies
    else:
        # ä»ä»£ç†æ± ä¸­éšæœºé€‰æ‹©ä¸€ä¸ªä»£ç†
        proxy_url = get_random_proxy()
        if proxy_url:
            current_proxy = create_proxy_dict(proxy_url)
            print(f"ä½¿ç”¨ä»£ç†æ± ä»£ç†: {current_proxy}")
            used_proxies.add(proxy_url)

    for retry in range(max_retries):
        try:
            client = (FlareSolverrHTTPClient(url=flaresolverr_url,
                                     proxy=flaresolverr_proxy,
                                     cookies=cookies,
                                     http2=True)
                if flaresolverr_url else httpx.Client(cookies=cookies, http2=True, proxies=current_proxy))

            @contextmanager
            def _request(method, url, *args, **kwargs):
                r = client.request(method=method, url=url,
                                   headers={
                                       'user-agent': DEFAULT_USER_AGENT,
                                       'x-requested-with': 'XMLHttpRequest',
                                       'dnt': '1',
                                       'accept': '*/*',
                                       'sec-ch-ua-mobile': '?0',
                                       'sec-ch-ua-platform': 'macOS',
                                       'sec-fetch-site': 'same-origin',
                                       'sec-fetch-mode': 'cors',
                                       'sec-fetch-dest': 'empty',
                                       'referer': f'https://{SEHUATANG_HOST}/plugin.php?id=dd_sign&mod=sign',
                                       'accept-language': 'en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7',
                                   }, *args, **kwargs)
                try:
                    r.raise_for_status()
                    yield r
                finally:
                    r.close()

            with client:
                age_confirmed = False
                age_retry_cnt = 3
                while not age_confirmed and age_retry_cnt > 0:
                    with _request(method='get', url=f'https://{SEHUATANG_HOST}/') as r:
                        if (v := re.findall(r"safeid='(\w+)'",
                                            r.text, re.MULTILINE | re.IGNORECASE)) and (safeid := v[0]):
                            print(f'set age confirm cookie: _safe={safeid}')
                            client.cookies.set(name='_safe', value=safeid)
                        else:
                            age_confirmed = True
                        age_retry_cnt -= 1

                if not age_confirmed:
                    raise Exception('failed to pass age confirmation')

                # éšæœºç­‰å¾…
                wait_time = random.randint(4, 10)
                print(f'åœ¨é€‰æ‹©é¢˜ç›®ä¹‹å‰ç­‰å¾… {wait_time} ç§’...')
                time.sleep(wait_time)
                # éšæœºç­‰å¾…

                with _request(method='get', url=f'https://{SEHUATANG_HOST}/forum.php?mod=forumdisplay&fid={FID}') as r:
                    tids = re.findall(r"normalthread_(\d+)", r.text,
                                      re.MULTILINE | re.IGNORECASE)
                    tid = random.choice(tids)
                    print(f'choose tid = {tid} to comment')

                # éšæœºç­‰å¾…
                wait_time = random.randint(4, 10)
                print(f'éšæœºç­‰å¾… {wait_time} ç§’...')
                time.sleep(wait_time)
                # éšæœºç­‰å¾…

                with _request(method='get', url=f'https://{SEHUATANG_HOST}/forum.php?mod=viewthread&tid={tid}&extra=page%3D1') as r:
                    soup = BeautifulSoup(r.text, 'html.parser')
                    formhash = soup.find('input', {'name': 'formhash'})['value']

                message = random.choice(AUTO_REPLIES)

                # éšæœºç­‰å¾…
                wait_time = random.randint(3, 10)
                print(f'éšæœºç­‰å¾… {wait_time} ç§’...')
                time.sleep(wait_time)
                # éšæœºç­‰å¾…
                with _request(method='post', url=f'https://{SEHUATANG_HOST}/forum.php?mod=post&action=reply&fid={FID}&tid={tid}&extra=page%3D1&replysubmit=yes&infloat=yes&handlekey=fastpost&inajax=1',
                              data={
                                  'file': '',
                                  'message': message,
                                  'posttime': int(time.time()),
                                  'formhash': formhash,
                                  'usesig': '',
                                  'subject': '',
                              }) as r:
                    print(f'comment to: tid = {tid}, message = {message}')

                with _request(method='get', url=f'https://{SEHUATANG_HOST}/plugin.php?id=dd_sign&mod=sign') as r:
                    # id_hash_rsl = re.findall(
                    #     r"updatesecqaa\('(.*?)'", r.text, re.MULTILINE | re.IGNORECASE)
                    # id_hash = id_hash_rsl[0] if id_hash_rsl else 'qS0'  # default value

                    # soup = BeautifulSoup(r.text, 'html.parser')
                    # formhash = soup.find('input', {'name': 'formhash'})['value']
                    # signtoken = soup.find('input', {'name': 'signtoken'})['value']
                    # action = soup.find('form', {'name': 'login'})['action']
                    pass
                #è·å–ä¸ªäººè´¦å·å
                # éšæœºç­‰å¾…
                wait_time = random.randint(1, 3)
                print(f'éšæœºç­‰å¾… {wait_time} ç§’...')
                time.sleep(wait_time)
                # éšæœºç­‰å¾…
                with _request(method='get', url=f'https://{SEHUATANG_HOST}/home.php?mod=spacecp&ac=profile') as r:
                    soup = BeautifulSoup(r.text, 'html.parser')
                    
                    # æŸ¥æ‰¾æ ‡ç­¾
                    username_element = soup.find('strong', class_='vwmy')

                    # æå–ç”¨æˆ·ä¿¡æ¯
                    if username_element:
                        username = username_element.text
                        # æ©ç å¤„ç†ï¼šä¿ç•™é¦–å­—æ¯å’Œæœ€åä¸€å­—æ¯ï¼Œå…¶ä»–éƒ¨åˆ†ç”¨æ˜Ÿå·ä»£æ›¿
                        def mask_username(username):
                            if len(username) <= 2:
                                # å¦‚æœç”¨æˆ·ååªæœ‰ä¸€ä¸¤ä½ï¼Œæ©ç ä¸€åŠæˆ–å®Œå…¨æ©ç›–
                                return username[0] + '*' * (len(username) - 1)
                            else:
                                return username[0] + '*' * (len(username) - 2) + username[-1]

                        masked_username = mask_username(username)
                        print(f"ç”¨æˆ·å: {masked_username}")
                    else:
                        print("æœªæ‰¾åˆ°ç”¨æˆ·å")

                    # è¾“å‡ºç»“æœ
                    output = f"ğŸ™‹â€â™‚ï¸ç”¨æˆ·å: {masked_username} \n"
                #è·å–é‡‘å¸ç­‰ä¿¡æ¯
                # éšæœºç­‰å¾…
                wait_time = random.randint(1, 3)
                print(f'éšæœºç­‰å¾… {wait_time} ç§’...')
                time.sleep(wait_time)
                # éšæœºç­‰å¾…
                with _request(method='get', url=f'https://{SEHUATANG_HOST}/home.php?mod=spacecp&ac=credit&showcredit=1') as r:
                    soup = BeautifulSoup(r.text, 'html.parser')
                   
                    # æŸ¥æ‰¾æ‰€æœ‰å¸¦æœ‰ <li> æ ‡ç­¾çš„ç§¯åˆ†ä¿¡æ¯

                    credit_info = soup.find_all('li')

                    # æå–ç§¯åˆ†å’Œé‡‘é’±ç­‰ä¿¡æ¯
                    credits = {}
                    first_integral_found = False
                    for item in credit_info:
                        if item.find('em'):  # æ£€æŸ¥æ˜¯å¦æœ‰ <em> æ ‡ç­¾
                            key = item.find('em').text.strip().replace(':', '')
                            value = item.text.split(":")[-1].strip()
                            if key == "ç§¯åˆ†" and not first_integral_found:
                                credits[key] = value
                                first_integral_found = True
                            elif key!= "ç§¯åˆ†":
                                credits[key] = value

                    # è·å–ç”¨æˆ·ç»„ä¿¡æ¯
                    user_group_tag = soup.find('a', {'id': 'g_upmine'})
                    user_group = user_group_tag.text.split(":")[-1].strip() if user_group_tag else 'æœªæ‰¾åˆ°'

                    # è·å–å„ç±»ç§¯åˆ†ä¿¡æ¯ï¼Œå¹¶è¿›è¡Œè¾“å‡ºæ ¼å¼åŒ–
                    gold = credits.get('é‡‘é’±', 'æœªæ‰¾åˆ°')
                    points = credits.get('ç§¯åˆ†', 'æœªæ‰¾åˆ°')
                    coins = credits.get('è‰²å¸', 'æœªæ‰¾åˆ°')
                    ratings = credits.get('è¯„åˆ†', 'æœªæ‰¾åˆ°')

                    # è¾“å‡ºç»“æœ
                    output += f"ğŸ¤¼â€â™‚ï¸ç”¨æˆ·ç»„ï¼š{user_group} \nğŸ’°é‡‘å¸ï¼š{gold}\nğŸ’¯ç§¯åˆ†ï¼š{points}\nğŸ˜è‰²å¸ï¼š{coins}\nğŸ”¥è¯„åˆ†ï¼š{ratings}\n"
                #è·å–å‡çº§è¯¦æƒ…
                # éšæœºç­‰å¾…
                wait_time = random.randint(1, 3)
                print(f'éšæœºç­‰å¾… {wait_time} ç§’...')
                time.sleep(wait_time)
                # éšæœºç­‰å¾…
                with _request(method='get', url=f'https://{SEHUATANG_HOST}/home.php?mod=spacecp&ac=usergroup') as r:
                    soup = BeautifulSoup(r.text, 'html.parser')
                    # è·å–æ™‹çº§ç”¨æˆ·ç»„ä¿¡æ¯
                    upgrade_usergroup = soup.find('li', {'id': 'c2'}).text
                    #print("æ™‹çº§ç”¨æˆ·ç»„ä¿¡æ¯:", upgrade_usergroup)

                    # æŸ¥æ‰¾åŒ…å«æ™‹çº§ç”¨æˆ·ç»„ä¿¡æ¯çš„div
                    tscr_div = soup.find('div', class_='tscr')

                    if tscr_div:
                        # æå–å‡çº§æ‰€éœ€ç§¯åˆ†ä¿¡æ¯
                        required_points = tscr_div.find('span', class_='notice').text
                        # ä»æ–‡æœ¬ä¸­æå–ç§¯åˆ†æ•°å­—
                        points_needed = int(required_points.split('ç§¯åˆ†')[1].strip())

                        # è®¡ç®—é¢„è®¡å‡çº§æ—¶é—´
                        points_per_day = 3
                        days_needed = points_needed / points_per_day

                        # æ‰‹åŠ¨å‘ä¸Šå–æ•´
                        if days_needed != int(days_needed):
                            days_needed_ceil = int(days_needed) + 1
                        else:
                            days_needed_ceil = int(days_needed)

                        # è®¡ç®—é¢„è®¡å‡çº§æ—¥æœŸ
                        today = datetime.now()
                        todayDate = today.date()  
                        upgrade_date = todayDate + timedelta(days=days_needed_ceil)
                    else:
                        print("æœªæ‰¾åˆ°åŒ…å«æ™‹çº§ç”¨æˆ·ç»„ä¿¡æ¯çš„ divã€‚")

                    # è¾“å‡ºç»“æœ
                    output += f"\n{upgrade_usergroup} \n{required_points}\n"
                    output += f"é¢„è®¡è¿˜éœ€{days_needed_ceil}å¤©\n"
                    output += f"é¢„è®¡å‡çº§æ—¶é—´: {upgrade_date}"
                return output

        except httpx.ProxyError as e:
            print(f"ä»£ç†é”™è¯¯: {str(e)}")
            if current_proxy:
                print(f"å½“å‰ä»£ç† {current_proxy} ä¸å¯ç”¨ï¼Œå°è¯•åˆ‡æ¢ä»£ç†...")
                # å°è¯•ä½¿ç”¨æ–°çš„ä»£ç†
                available_proxies = [p for p in proxy_pool if p not in used_proxies]
                if available_proxies:
                    proxy_url = random.choice(available_proxies)
                    current_proxy = create_proxy_dict(proxy_url)
                    used_proxies.add(proxy_url)
                    print(f"åˆ‡æ¢åˆ°æ–°ä»£ç†: {current_proxy}")
                    time.sleep(retry_delay)
                    continue
                else:
                    print("æ‰€æœ‰ä»£ç†éƒ½å·²å°è¯•è¿‡ï¼Œæ— æ³•ç»§ç»­")
                    raise Exception("æ‰€æœ‰ä»£ç†éƒ½ä¸å¯ç”¨")
            else:
                raise Exception(f"ä»£ç†é”™è¯¯: {str(e)}")

        except httpx.RequestError as e:
            print(f"è¯·æ±‚é”™è¯¯: {str(e)}")
            if retry < max_retries - 1:
                print(f"ç­‰å¾… {retry_delay} ç§’åé‡è¯•...")
                time.sleep(retry_delay)
                continue
            else:
                raise Exception(f"è¯·æ±‚é”™è¯¯: {str(e)}")

        except Exception as e:
            print(f"æœªçŸ¥é”™è¯¯: {str(e)}")
            traceback.print_exc()
            if retry < max_retries - 1:
                print(f"ç­‰å¾… {retry_delay} ç§’åé‡è¯•...")
                time.sleep(retry_delay)
                continue
            else:
                raise Exception(f"æœªçŸ¥é”™è¯¯: {str(e)}")

def retrieve_cookies_from_curl(env: str) -> dict:
    cURL = os.getenv(env, '').replace('\\', ' ')
    try:
        import uncurl
        return uncurl.parse_context(curl_command=cURL).cookies
    except ImportError:
        print("uncurl is required.")


def retrieve_cookies_from_fetch(env: str) -> dict:
    def parse_fetch(s: str) -> dict:
        ans = {}
        exec(s, {
            'fetch': lambda _, o: ans.update(o),
            'null': None
        })
        return ans
    cookie_str = parse_fetch(os.getenv(env))['headers']['cookie']
    return dict(s.strip().split('=', maxsplit=1) for s in cookie_str.split(';'))


def preprocess_text(text) -> str:
    if 'xml' not in text:
        return text

    try:
        root = ET.fromstring(text)
        cdata = root.text
        soup = BeautifulSoup(cdata, 'html.parser')
        for script in soup.find_all('script'):
            script.decompose()
        return soup.get_text()
    except:
        return text


def push_notification(title: str, content: str) -> None:

    def telegram_send_message(text: str, chat_id: str, token: str, silent: bool = False) -> None:
        r = httpx.post(url=f'https://api.telegram.org/bot{token}/sendMessage',
                       json={
                           'chat_id': chat_id,
                           'text': text,
                           'disable_notification': silent,
                           'disable_web_page_preview': True,
                       })
        r.raise_for_status()

    try:
        from notify import telegram_bot
        telegram_bot(title, content)
    except ImportError:
        chat_id = os.getenv('TG_USER_ID')
        bot_token = os.getenv('TG_BOT_TOKEN')
        if chat_id and bot_token:
            telegram_send_message(f'{title}\n\n{content}', chat_id, bot_token)


def main():
    raw_html = None
    results = []  # ç”¨äºå­˜å‚¨æ‰€æœ‰è¯„è®ºç»“æœ

    # éå†å¤šä¸ª FETCH_98TANG ç¯å¢ƒå˜é‡
    fetch_index = 1
    while os.getenv(f'FETCH_98TANG_{fetch_index}'):
        try:
            # è·å– cookies
            cookies = retrieve_cookies_from_fetch(f'FETCH_98TANG_{fetch_index}')
            
            # è·å–å¯¹åº”çš„ä»£ç†
            proxy = os.getenv(f'DEAULT_PROXY_{fetch_index}', None)
            if proxy:
                proxies = {'http': proxy, 'https': proxy}
                print(f"è´¦å· {fetch_index} ä½¿ç”¨ç¯å¢ƒå˜é‡ä»£ç†: {proxies}")
            else:
                proxies = None
                # ç§»é™¤é”™è¯¯æç¤ºï¼Œç›´æ¥ä½¿ç”¨ä»£ç†æ± 
                print(f"è´¦å· {fetch_index} ä½¿ç”¨ä»£ç†æ± ")

            # æ‰§è¡Œè¯„è®ºï¼Œå¹¶ä¼ é€’ä»£ç†ä¿¡æ¯
            raw_html = daysign(
                cookies=cookies,
                flaresolverr_url=os.getenv('FLARESOLVERR_URL'),
                flaresolverr_proxy=os.getenv('FLARESOLVERR_PROXY'),
                proxies=proxies
            )

            if 'ç§¯åˆ†' in raw_html:
                title = f'ç¬¬{fetch_index}ä¸ªè´¦å· ç§¯åˆ†è¯¦æƒ…\n'
                message_text = raw_html
            else:
                title = f'ç¬¬{fetch_index}ä¸ªè´¦å· è¯„è®ºå¼‚å¸¸'
                message_text = raw_html

        except Exception as e:
            title = f'ç¬¬{fetch_index}ä¸ªè´¦å· è¯„è®ºå¼‚å¸¸'
            message_text = f'é”™è¯¯åŸå› ï¼š{str(e)}\nè¯¦ç»†é”™è¯¯ä¿¡æ¯ï¼š{traceback.format_exc()}'
            print(f"è´¦å· {fetch_index} è¯„è®ºå¤±è´¥: {message_text}")

        # å¤„ç†å¹¶ä¿å­˜ç»“æœ
        message_text = preprocess_text(message_text)
        results.append(f'{title}\n{message_text}')
        
        fetch_index += 1

    # è¾“å‡ºæ‰€æœ‰ç»“æœ
    for result in results:
        print(result)

    #é’é¾™é€šçŸ¥
    full_message = "\n\n".join(results)
    from notify import send
    send('ğŸ—“98å ‚è¯„è®º', full_message)



if __name__ == '__main__':
    main()
